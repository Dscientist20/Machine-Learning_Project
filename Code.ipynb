{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Machine learning for classification.\n",
    "\n",
    "Le but de ce projet est d'étudier la capacité de plusieurs machines d'apprentissage à construire un classificateur de chiffres manuscrits. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réaliser par:\n",
    "     1- Djiomou Ngongang Cédric Charly\n",
    "     2- Babou Traore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis,LinearDiscriminantAnalysis\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description\n",
    "\n",
    "The dataset contains a sample of handwritten digits. Each digit is described by an image of 8 ∗ 8 pixels in normalized grayscale.\n",
    "there are 64 features and 1797 instances. The target data contains 9 categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X=digits.data;\n",
    "y=digits.target;\n",
    "obs=X[100,:]; label=y[100];\n",
    "image=np.array(obs, dtype='uint8').reshape(8,8);\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données\n",
    "\n",
    " Le traitement des données consistera simplement pour nous à réduire les données au seules données correspondant aux deux digits choisis.\n",
    " \n",
    " Une fois fait, nous obtenons 350 observations sur 1797 au départ qui représente une perte énorme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing dataset.\n",
    "# transforms target data\n",
    "# Our digits choices\n",
    "digit=[0,8]\n",
    "def transforms(digit= digit,method=1):\n",
    "    # method= 1:remove all data which are different from the digit input\n",
    "    # method= different from 1: We  trasform into -10 all data which are different from 0 and 8,and into 10 else\n",
    "    # digit: Our target choices. Could be different.\n",
    "    target=digit \n",
    "    if method==1:\n",
    "        index=[]\n",
    "        for i in range(len(y)):\n",
    "            if y[i] not in target:\n",
    "                index.append(i)\n",
    "        # delete data different from 0 and 8\n",
    "        y_target=np.delete(y,index)\n",
    "        X_features=np.delete(X,index,axis=0)\n",
    "    else:\n",
    "        y_target=[]\n",
    "        for i in y:\n",
    "            if i in target:\n",
    "                y_target.append(10)\n",
    "            else: \n",
    "                y_target.append(-10)\n",
    "        X_features=X\n",
    "        \n",
    "    return(y_target,X_features)    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage et validation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use in the whole project\n",
    "def dataframe(train_score,test_score,score):\n",
    "    res=pd.DataFrame([round(train_score,4)*100,round(test_score,4)*100,round(score,4)*100],index=[\"Trainset\",\"Testset\",\"Dataset\"])\n",
    "    res.columns=[\"Accuracy(%)\"]\n",
    "    return(res)  \n",
    "# fonction qui nous aidera à afficher les résultats sous forme de tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test part\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_features, y_target, test_size=.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainset</th>\n",
       "      <td>99.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testset</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>99.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy(%)\n",
       "Trainset        99.53\n",
       "Testset        100.00\n",
       "Dataset         99.72"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naives Bayes\n",
    "\n",
    "gnb = GaussianNB();\n",
    "gnbfit=gnb.fit(X_train, Y_train);\n",
    "dataframe(train_score=gnb.score(X_train, Y_train),test_score=gnb.score(X_test, Y_test),score=gnb.score(X_features, y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainset</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testset</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy(%)\n",
       "Trainset        100.0\n",
       "Testset         100.0\n",
       "Dataset         100.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Discriminant Analysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='lsqr');\n",
    "ldafit=lda.fit(X_train,Y_train)\n",
    "dataframe(train_score=lda.score(X_train, Y_train),test_score=lda.score(X_test, Y_test),score=lda.score(X_features, y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainset</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testset</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy(%)\n",
       "Trainset        100.0\n",
       "Testset         100.0\n",
       "Dataset         100.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic regression\n",
    "\n",
    "lgr = linear_model.LogisticRegression(solver=\"lbfgs\");\n",
    "lgrfit=lgr.fit(X_train,Y_train)\n",
    "dataframe(train_score=lgr.score(X_train, Y_train),test_score=lgr.score(X_test, Y_test),score=lgr.score(X_features, y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainset</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testset</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy(%)\n",
       "Trainset        100.0\n",
       "Testset         100.0\n",
       "Dataset         100.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neighbors\n",
    " \n",
    "knn=KNeighborsClassifier()\n",
    "knnfit=knn.fit(X_train,Y_train)\n",
    "dataframe(train_score=knn.score(X_train, Y_train),test_score=knn.score(X_test, Y_test),score=knn.score(X_features, y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainset</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testset</th>\n",
       "      <td>98.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>99.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy(%)\n",
       "Trainset       100.00\n",
       "Testset         98.58\n",
       "Dataset         99.43"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "treefit = tree.fit(X_train, Y_train);\n",
    "dataframe(train_score=tree.score(X_train, Y_train),test_score=tree.score(X_test, Y_test),score=tree.score(X_features, y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NBayes</th>\n",
       "      <th>KNeighbors</th>\n",
       "      <th>LDA</th>\n",
       "      <th>Logreg</th>\n",
       "      <th>Dtree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training set</th>\n",
       "      <td>99.53</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test set</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>99.72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              NBayes  KNeighbors    LDA  Logreg  Dtree\n",
       "Training set   99.53       100.0  100.0   100.0  100.0\n",
       "Test set      100.00       100.0  100.0   100.0  100.0\n",
       "Dataset        99.72       100.0  100.0   100.0  100.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of all Classifiers\n",
    "\n",
    "names=[\"NBayes\",\"KNeighbors\",\"LDA\",\"Logreg\",\"Dtree\"]\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(n_neighbors=2),\n",
    "    LinearDiscriminantAnalysis(solver='lsqr'),\n",
    "    linear_model.LogisticRegression(solver='lbfgs'),\n",
    "    DecisionTreeClassifier(),\n",
    "    ]\n",
    "train_score=[]\n",
    "test_score=[]\n",
    "dataset_score=[]\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    train_score.append(round(clf.score(X_train, Y_train),4)*100)\n",
    "    test_score.append(round(clf.score(X_test, Y_test),4)*100)\n",
    "    dataset_score.append(round(clf.score(X_features,y_target),4)*100)\n",
    "        \n",
    "        \n",
    "\n",
    "Accuracy=pd.DataFrame([train_score,test_score,dataset_score],index=[\"Training set\",\"Test set\",\"Dataset\"])\n",
    "Accuracy.columns=names\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Nous remarquons à l'issue de l'entraînement de ces quatre classifieurs, une performance de 100% sur les données d'entraînement, de test et sur l'ensemble des données pour tous les modèles sauf ceux du  Naive Bayes qui sont tout de même proche de 100%.  nous allons essayer d'améliorer avec les méthoses d'ensemble. \n",
    "  \n",
    "  La précision de l'arbre à décision est de 100% en entraînement et de 99.29 en génération avec une légère variance de moins de 1%. Nous aimerions que la performance en génération soit aumoins égale à la performance en entraînement. Nous essayerons de l'améliorer.\n",
    "  \n",
    "  Une performance de 100% laisserait penser que nos modèles sont parfaits.Toutefois nous sommes plutôt sceptiques quant à ces valeurs et soupçonons que la quantité insuffisante des données qui est davantage réduite avec la méthode de recodage de notre variabe cible pourrait expliquer une telle performance.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amélioration de la performance du modèle Gaussien et de l'arbre à décision\n",
    "\n",
    " En temps normal, la précision de 99.53% obtenues pour le modèle gaussien est en principe une bonne performance pour un modèle mais pour des raisons pédagogiques, nous essayerons de voir l'impact des méthodes d'ensembles telles que le random forest, le Bagging et l'Adaboost sur la performance.\n",
    " \n",
    " Nous allons donc utiliser le random forest pour l'arbre à décision et le Bagging et l'Adaboost pour les deux modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>35</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training set</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test set</th>\n",
       "      <td>99.29</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>99.72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  10     15     20     25     30     35     40\n",
       "Training set  100.00  100.0  100.0  100.0  100.0  100.0  100.0\n",
       "Test set       99.29  100.0  100.0  100.0  100.0  100.0  100.0\n",
       "Dataset        99.72  100.0  100.0  100.0  100.0  100.0  100.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest pour l'arbre à décision\n",
    "\n",
    "# Training with various n_estimators\n",
    "n=[10,15,20,25,30,35,40]\n",
    "train_score_RF=[]\n",
    "test_score_RF=[]\n",
    "score_RF=[]\n",
    "for i in n:\n",
    "    RF = RandomForestClassifier(random_state=0,n_estimators=i)\n",
    "    RFfit=RF.fit(X_train, Y_train)\n",
    "    train_score_RF.append(round(RFfit.score(X_train, Y_train),4)*100)\n",
    "    test_score_RF.append(round(RFfit.score(X_test, Y_test),4)*100)\n",
    "    score_RF.append(round(RFfit.score(X_features, y_target),4)*100)\n",
    "    \n",
    "    \n",
    "Accuracy_RF=pd.DataFrame([train_score_RF,test_score_RF,score_RF],index=[\"Training set\",\"Test set\",\"Dataset\"])\n",
    "Accuracy_RF.columns=n\n",
    "Accuracy_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La performance du modèle de l'arbre à décision s'améliore avec le random forest à partir de 15 arbres en  entrée.\n",
    "\n",
    "Nous allons regarder ce qu'il en est du Boosting et du Bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost pour: NBayes \n",
      "                   10      15      20      25      30      35      40      50\n",
      "Training set  100.00  100.00  100.00  100.00  100.00  100.00  100.00  100.00\n",
      "Test set       98.58   98.58   98.58   98.58   98.58   98.58   98.58   98.58\n",
      "Dataset        99.43   99.43   99.43   99.43   99.43   99.43   99.43   99.43 \n",
      "\n",
      "Adaboost pour: Dtree \n",
      "                  10     15     20      25     30     35     40      50\n",
      "Training set  100.0  100.0  100.0  100.00  100.0  100.0  100.0  100.00\n",
      "Test set      100.0  100.0  100.0   98.58  100.0  100.0  100.0   98.58\n",
      "Dataset       100.0  100.0  100.0   99.43  100.0  100.0  100.0   99.43 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adaboost pour les deux modèles\n",
    "names1=[\"NBayes\",\"Dtree\"]\n",
    "classifiers1 = [GaussianNB(),DecisionTreeClassifier()]\n",
    "n=[10,15,20,25,30,35,40,50]\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names1, classifiers1):\n",
    "    train_score_ab1=[]\n",
    "    test_score_ab1=[]\n",
    "    score_ab1=[]\n",
    "# Training with various n_estimators\n",
    "    for i in n:\n",
    "        Ab1 = AdaBoostClassifier(base_estimator=clf,n_estimators=i)\n",
    "        Ab1fit=Ab1.fit(X_train, Y_train)\n",
    "        train_score_ab1.append(round(Ab1fit.score(X_train, Y_train),4)*100)\n",
    "        test_score_ab1.append(round(Ab1fit.score(X_test, Y_test),4)*100)\n",
    "        score_ab1.append(round(Ab1fit.score(X_features, y_target),4)*100)\n",
    "    \n",
    "    \n",
    "    Accuracy_ab=pd.DataFrame([train_score_ab1,test_score_ab1,score_ab1],index=[\"Training set\",\"Test set\",\"Dataset\"])\n",
    "    Accuracy_ab.columns=n\n",
    "    print(\"Adaboost pour:\",name,\"\\n\",Accuracy_ab,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Tout d'abord, on remarque que le biais du modèle du Naive Bayes est améliorée par l'adaboost mais la variance est détériorée. Le modèle Naive Bayes est préféré à son corrolaire Adaboost.\n",
    " \n",
    "  Ensuite, la performance globale de l'arbre à décision est également améliorée avec l'Adaboost à 10 arbres quand le random forest le fait avec 15 arbres. Nous préferons donc le modèle d'arbres à décision à 10 arbres. \n",
    "  \n",
    " Qu'en est-il du bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging pour: NBayes \n",
      "                   10     15      20      25      30      35      40      50\n",
      "Training set   99.53  99.53   99.53   99.53   99.53   99.53   99.53   99.53\n",
      "Test set      100.00  99.29  100.00  100.00  100.00  100.00  100.00  100.00\n",
      "Dataset        99.72  99.43   99.72   99.72   99.72   99.72   99.72   99.72 \n",
      "\n",
      "Bagging pour: Dtree \n",
      "                   10     15      20      25      30      35     40      50\n",
      "Training set  100.00  99.53  100.00  100.00  100.00  100.00  100.0  100.00\n",
      "Test set       99.29  99.29   99.29   99.29   99.29   99.29  100.0   99.29\n",
      "Dataset        99.72  99.43   99.72   99.72   99.72   99.72  100.0   99.72 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bagging pour les deux modèles\n",
    "names1=[\"NBayes\",\"Dtree\"]\n",
    "classifiers1 = [GaussianNB(),DecisionTreeClassifier()]\n",
    "n=[10,15,20,25,30,35,40,50]\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names1, classifiers1):\n",
    "    train_score_bg1=[]\n",
    "    test_score_bg1=[]\n",
    "    score_bg1=[]\n",
    "# Training with various n_estimators\n",
    "    for i in n:\n",
    "        bg1 = BaggingClassifier(base_estimator=clf,n_estimators=i)\n",
    "        bg1fit=bg1.fit(X_train, Y_train)\n",
    "        train_score_bg1.append(round(bg1fit.score(X_train, Y_train),4)*100)\n",
    "        test_score_bg1.append(round(bg1fit.score(X_test, Y_test),4)*100)\n",
    "        score_bg1.append(round(bg1fit.score(X_features, y_target),4)*100)\n",
    "    \n",
    "    \n",
    "    Accuracy_bg1=pd.DataFrame([train_score_bg1,test_score_bg1,score_bg1],index=[\"Training set\",\"Test set\",\"Dataset\"])\n",
    "    Accuracy_bg1.columns=n\n",
    "    print(\"Bagging pour:\",name,\"\\n\",Accuracy_bg1,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Le bagging conserve le même modèle du Naive Bayes classique et le même modèle de l'arbre à décision classique.\n",
    " \n",
    " En résumé pour cette methode de recodage de la variable cible, le meilleur classifieur:\n",
    " \n",
    " pour le Naive Baye est celui du Naive Bayes classique.\n",
    " pour l'arbre à décision est celui avec le Adaboost avec 10 arbres\n",
    " Pour le LDA,KNN et logistique, est leur modèle classique.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les meilleurs modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NBayes</th>\n",
       "      <th>KNeighbors</th>\n",
       "      <th>LDA</th>\n",
       "      <th>Logreg</th>\n",
       "      <th>Adaboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training set</th>\n",
       "      <td>99.53</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test set</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>99.72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              NBayes  KNeighbors    LDA  Logreg  Adaboost\n",
       "Training set   99.53       100.0  100.0   100.0    100.00\n",
       "Test set      100.00       100.0  100.0   100.0     98.58\n",
       "Dataset        99.72       100.0  100.0   100.0     99.43"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En résumé\n",
    "\n",
    "names=[\"NBayes\",\"KNeighbors\",\"LDA\",\"Logreg\",\"Adaboost\"]\n",
    "classifiers_best = [\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    LinearDiscriminantAnalysis(solver='lsqr'),\n",
    "    linear_model.LogisticRegression(solver='lbfgs'),\n",
    "    AdaBoostClassifier(base_estimator=clf,n_estimators=10),\n",
    "    ]\n",
    "train_score_best=[]\n",
    "test_score_best=[]\n",
    "dataset_score_best=[]\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers_best):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    train_score_best.append(round(clf.score(X_train, Y_train),4)*100)\n",
    "    test_score_best.append(round(clf.score(X_test, Y_test),4)*100)\n",
    "    dataset_score_best.append(round(clf.score(X_features,y_target),4)*100)\n",
    "        \n",
    "        \n",
    "\n",
    "Accuracy_best=pd.DataFrame([train_score_best,test_score_best,dataset_score_best],index=[\"Training set\",\"Test set\",\"Dataset\"])\n",
    "Accuracy_best.columns=names\n",
    "Accuracy_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Pour le choix d'un modèle, nous écartons le Naive bayes et sommes indifférents pour les quatre autres."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
